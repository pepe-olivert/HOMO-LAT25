{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pepe/miniconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "import ast\n",
    "import random\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path_to_dataset):\n",
    "    return pd.read_csv(path_to_dataset, index_col = 0)\n",
    "\n",
    "def extract_similar_descriptions(e, embeddings, k):\n",
    "    similarities = cosine_similarity([e], embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[-k:][::-1]\n",
    "    return top_indices\n",
    "    \n",
    "def compute_embeddings_distance(embedding_str, k, df):\n",
    "    #df = load_dataset(path_to_dataset)\n",
    "\n",
    "    # QUitamos del dataset la misma fila con la que estamos trabajando\n",
    "    df = df[df[\"embeddings\"]!= embedding_str]\n",
    "\n",
    "    def parse_embedding(embedding_str):\n",
    "        embedding_str = embedding_str.strip(\"[]\")\n",
    "        return np.array(embedding_str.split(), dtype=np.float32)\n",
    "    \n",
    "    embedding = parse_embedding(embedding_str)\n",
    "    df[\"embeddings\"] = df[\"embeddings\"].apply(lambda x: parse_embedding(x))\n",
    "\n",
    "    df_pos = df[df[\"label\"]==2]\n",
    "    df_neu = df[df[\"label\"]==1]\n",
    "    df_neg = df[df[\"label\"]==0]\n",
    "\n",
    "    pos_description_embeddings = np.vstack(df_pos[\"embeddings\"].values)\n",
    "    pos_nearest_descriptions = extract_similar_descriptions(embedding, pos_description_embeddings, k)\n",
    "    pos_result = df_pos.iloc[pos_nearest_descriptions][\"post content\"]\n",
    "\n",
    "    neu_description_embeddings = np.vstack(df_neu[\"embeddings\"].values)\n",
    "    neu_nearest_descriptions = extract_similar_descriptions(embedding, neu_description_embeddings, k)\n",
    "    neu_result = df_neu.iloc[neu_nearest_descriptions][\"post content\"]\n",
    "\n",
    "    neg_description_embeddings = np.vstack(df_neg[\"embeddings\"].values)\n",
    "    neg_nearest_descriptions = extract_similar_descriptions(embedding, neg_description_embeddings, k)\n",
    "    neg_result = df_neg.iloc[neg_nearest_descriptions][\"post content\"]\n",
    "    \n",
    "\n",
    "    return pos_result.to_list(), neu_result.to_list(), neg_result.to_list()\n",
    "\n",
    "mapping = {\"NEG\":0, \"NEU\":1, \"POS\":2}\n",
    "\n",
    "def label2int(label):\n",
    "    return mapping[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device count: 1\n",
      "Current device: 0\n",
      "NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device count:\", torch.cuda.device_count())\n",
    "    print(\"Current device:\", torch.cuda.current_device())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_dataset(\"../data/train_paraphrased.csv\")\n",
    "test_df = load_dataset(\"../data/test_paraphrased.csv\")\n",
    "val_df = load_dataset(\"../data/val_paraphrased.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([0.9808, 0.6057, 3.0354], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, paraphrases, labels, tokenizer, k, df, type = None, augmentation = False, local_database = train_df):\n",
    "        super().__init__() \n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.k = k\n",
    "        self.df = df\n",
    "        self.local_database = local_database\n",
    "        self.paraphrases = paraphrases\n",
    "        self.type = type\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # DATA AUG\n",
    "        if self.type == \"train\" and self.augmentation:\n",
    "            paraphrase = self.paraphrases[idx]\n",
    "            samples = ast.literal_eval(paraphrase)\n",
    "            samples=list(samples)\n",
    "            samples.append(text)\n",
    "            text = random.choice(samples)\n",
    "            index = samples.index(text)\n",
    "\n",
    "\n",
    "            if index == 0:\n",
    "                embedding_str = self.df.loc[self.df[\"paraphrase_esp\"] == paraphrase, \"embedding_paraphrase_esp1\"].values[0]\n",
    "            elif index == 1:\n",
    "                embedding_str = self.df.loc[self.df[\"paraphrase_esp\"] == paraphrase, \"embedding_paraphrase_esp2\"].values[0]\n",
    "            else: \n",
    "                embedding_str = self.df.loc[self.df[\"post content\"] == text, \"embeddings\"].values[0]\n",
    "\n",
    "            words = text.split()\n",
    "            if random.random() < 0.3:\n",
    "            \n",
    "                if len(words) > 1:\n",
    "                    num_to_remove = max(1, int(0.1 * len(words)))  # Quitar ~10% de las palabras\n",
    "                    indices_to_remove = random.sample(range(len(words)), num_to_remove)\n",
    "                    words = [w for i, w in enumerate(words) if i not in indices_to_remove]\n",
    "                    text = \" \".join(words)\n",
    "\n",
    "                if random.random() < 0.3:\n",
    "\n",
    "                    if len(words) > 1:\n",
    "                        random.shuffle(words)\n",
    "                        text = \" \".join(words)\n",
    "\n",
    "        else:\n",
    "            embedding_str = embedding_str = self.df.loc[self.df[\"post content\"] == text, \"embeddings\"].values[0]\n",
    "        \n",
    "        # Obtener los textos más similares por clase\n",
    "        pos_texts, neu_texts, neg_texts = compute_embeddings_distance(embedding_str, self.k, self.local_database)\n",
    "        # Tokenizar el texto principal\n",
    "        encoding = self.tokenizer(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "        # Tokenizar los textos más similares\n",
    "        pos_tokens = self.tokenizer(pos_texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "        neu_tokens = self.tokenizer(neu_texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "        neg_tokens = self.tokenizer(neg_texts, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "        \n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "            \"pos_tokens\": pos_tokens[\"input_ids\"],\n",
    "            \"neu_tokens\": neu_tokens[\"input_ids\"],\n",
    "            \"neg_tokens\": neg_tokens[\"input_ids\"],\n",
    "            \"pos_attention\": pos_tokens[\"attention_mask\"],\n",
    "            \"neu_attention\": neu_tokens[\"attention_mask\"],\n",
    "            \"neg_attention\": neg_tokens[\"attention_mask\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"pysentimiento/robertuito-sentiment-analysis\")\n",
    "\n",
    "train_dataset = SentimentDataset(\n",
    "    texts=train_df[\"post content\"].tolist(),\n",
    "    labels=train_df[\"label\"].tolist(),\n",
    "    paraphrases=train_df[\"paraphrase_esp\"].tolist(),\n",
    "    tokenizer=tokenizer,\n",
    "    k=1,  # Número de mensajes similares a recuperar\n",
    "    df = train_df,\n",
    "    type = \"train\",\n",
    "    augmentation=False\n",
    ")\n",
    "\n",
    "val_dataset = SentimentDataset(\n",
    "    texts=val_df[\"post content\"].tolist(),\n",
    "    labels=val_df[\"label\"].tolist(),\n",
    "    paraphrases = [],\n",
    "    tokenizer=tokenizer,\n",
    "    k=1,  # Número de mensajes similares a recuperar\n",
    "    df = val_df\n",
    ")\n",
    "\n",
    "test_dataset = SentimentDataset(\n",
    "    texts=test_df[\"post content\"].tolist(),\n",
    "    labels=test_df[\"label\"].tolist(),\n",
    "    paraphrases = [],\n",
    "    tokenizer=tokenizer,\n",
    "    k=1,  # Número de mensajes similares a recuperar\n",
    "    df = test_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "Text: ni idea quin es yo conozco a elon muse que es amigo de donald trans y miler\n",
      "Label: 1\n",
      "Input IDs: tensor([    0,   648,  2606,  3554,   442,   560,  4324,   412,   459,   434,\n",
      "        12125,   443,   442,  1575,   413, 10227,  1531,   445,  1247,   416,\n",
      "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Positives: tensor([[    0,   507,  1575,   442,   459,  1531,   459, 15367,   660,   442,\n",
      "         11691,  1203,   575,     2,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1]])\n",
      "Neutral: tensor([[   0,  413, 1069,  442,  443,  452, 2399,  973,  723, 7856, 1082,  443,\n",
      "         2478,  552, 2281,  461,  471, 1531, 4046,    2,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1]])\n",
      "Negatives: tensor([[   0,  497,  413, 1531,  796, 1806,  235,  516, 3766,  454,  446, 6671,\n",
      "          445,  474, 1134,   56,  895,  452,  446,  481,    2,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1]])\n",
      "Positives: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Neutral: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Negatives: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    sample = train_dataset[i]\n",
    "    print(f\"Sample {i + 1}:\")\n",
    "    print(f\"Text: {train_dataset.texts[i]}\")\n",
    "    print(f\"Label: {sample['labels'].item()}\")\n",
    "    print(f\"Input IDs: {sample['input_ids']}\")\n",
    "    print(f\"Attention Mask: {sample['attention_mask']}\")\n",
    "    print(f\"Positives: {sample['pos_tokens']}\")\n",
    "    print(f\"Neutral: {sample['neu_tokens']}\")\n",
    "    print(f\"Negatives: {sample['neg_tokens']}\")\n",
    "    print(f\"Positives: {sample['pos_attention']}\")\n",
    "    print(f\"Neutral: {sample['neu_attention']}\")\n",
    "    print(f\"Negatives: {sample['neg_attention']}\")\n",
    "    print(\"\\n\" + \"-\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
    "    # Compute the dot products between Q and K, then scale by the square root of the key dimension\n",
    "    d_k = Q.size(-1)\n",
    "    scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
    "\n",
    "    # Apply mask if provided (useful for masked self-attention in transformers)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "    # Softmax to normalize scores, producing attention weights\n",
    "    attention_weights = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    # Compute the final output as weighted values\n",
    "    output = torch.matmul(attention_weights, V)\n",
    "    return output, attention_weights\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        # Define linear transformations for Q, K, V\n",
    "        self.query = nn.Linear(embed_size, embed_size)\n",
    "        self.key = nn.Linear(embed_size, embed_size)\n",
    "        self.value = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        # Generate Q, K, V matrices\n",
    "        Q = self.query(q)\n",
    "        K = self.key(k)\n",
    "        V = self.value(v)\n",
    "        \n",
    "        # Calculate attention using our scaled dot-product function\n",
    "        out, _ = scaled_dot_product_attention(Q, K, V)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at pysentimiento/robertuito-sentiment-analysis and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "class SentimentClassifierWithMultiAttention(nn.Module):\n",
    "    def __init__(self, base_model_name, num_labels=3, num_heads=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = AutoModel.from_pretrained(base_model_name)\n",
    "\n",
    "        self.attention_positive = nn.MultiheadAttention(embed_dim=768, num_heads=num_heads, batch_first=True)\n",
    "        self.attention_negative = nn.MultiheadAttention(embed_dim=768, num_heads=num_heads, batch_first=True)\n",
    "        self.attention_neutral = nn.MultiheadAttention(embed_dim=768, num_heads=num_heads, batch_first=True)\n",
    "        \"\"\"self.attention_positive = SelfAttention(768)\n",
    "        self.attention_negative = SelfAttention(768)\n",
    "        self.attention_neutral = SelfAttention(768)\"\"\"\n",
    "\n",
    "\n",
    "        self.linear_intermediate = nn.Linear(768 * 4, 768)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(768, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None, pos_tokens=None, neu_tokens=None, neg_tokens=None, pos_attention=None, neu_attention = None, neg_attention = None):\n",
    "        \n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]  # Token CLS\n",
    "        cls_embedding_expanded = cls_embedding.unsqueeze(1)\n",
    "\n",
    "        pos_outputs_0 = self.bert(pos_tokens[:,0,:], attention_mask=pos_attention[:,0,:])\n",
    "        pos_cls_embedding_0 = pos_outputs_0.last_hidden_state[:, 0, :]\n",
    "        pos_cls_embedding_0 = pos_cls_embedding_0.unsqueeze(1)  \n",
    "\n",
    "        pos_cls_embedding = pos_cls_embedding_0\n",
    "\n",
    "        neu_outputs_0 = self.bert(neu_tokens[:,0,:], attention_mask=neu_attention[:,0,:])\n",
    "        neu_cls_embedding_0 = neu_outputs_0.last_hidden_state[:, 0, :]\n",
    "        neu_cls_embedding_0 = neu_cls_embedding_0.unsqueeze(1)  \n",
    "\n",
    "        neu_cls_embedding = neu_cls_embedding_0\n",
    "\n",
    "        neg_outputs_0 = self.bert(neg_tokens[:,0,:], attention_mask=neg_attention[:,0,:])\n",
    "        neg_cls_embedding_0 = neg_outputs_0.last_hidden_state[:, 0, :]\n",
    "        neg_cls_embedding_0 = neg_cls_embedding_0.unsqueeze(1)  \n",
    "\n",
    "        neg_cls_embedding = neg_cls_embedding_0\n",
    "\n",
    "        cls_embedding_expanded = cls_embedding_expanded.float()\n",
    "        pos_cls_embedding = pos_cls_embedding.float()\n",
    "        neg_cls_embedding = neg_cls_embedding.float()\n",
    "        neu_cls_embedding = neu_cls_embedding.float()\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        Cada salida (attn_pos, attn_neg, attn_neut) representa una versión contextualizada del cls_embedding \n",
    "        influenciada por los mensajes de su respectiva clase. Es decir, el embedding [CLS] de entrada ha sido \n",
    "        modificado en función de lo que \"aprendió\" al atender a los mensajes positivos, negativos o neutros.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"attn_pos = self.attention_positive(cls_embedding_expanded, pos_cls_embedding, cls_embedding_expanded)\n",
    "        attn_neg = self.attention_negative(cls_embedding_expanded, neg_cls_embedding, cls_embedding_expanded)\n",
    "        attn_neut = self.attention_neutral(cls_embedding_expanded, neu_cls_embedding, cls_embedding_expanded)\"\"\"\n",
    "\n",
    "        attn_pos, _ = self.attention_positive(cls_embedding_expanded, pos_cls_embedding, cls_embedding_expanded)\n",
    "        attn_neg, _ = self.attention_negative(cls_embedding_expanded, neg_cls_embedding, cls_embedding_expanded)\n",
    "        attn_neut, _ = self.attention_neutral(cls_embedding_expanded, neu_cls_embedding, cls_embedding_expanded)\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        En este punto hemos sacado un nuevo embedding aplicando la capa de atencion del embedding entrante con los dos embeddings de cada clase siendo:\n",
    "        Q = embedding entrante\n",
    "        K = clase_emb\n",
    "        V = embedding entrante\n",
    "\n",
    "        Porque si V = clase_emb entonces:\n",
    "        Si pasas clase_emb como V, entonces el mecanismo de atención devolverá una combinación ponderada de los embeddings de la clase POSITIVA, \n",
    "        determinada por la similitud entre cls_embedding_expanded (Q) y clase_emb (K).\n",
    "        \"\"\"\n",
    "\n",
    "        combined_embedding = torch.cat([\n",
    "            cls_embedding,\n",
    "            attn_pos.squeeze(1),\n",
    "            attn_neg.squeeze(1),\n",
    "            attn_neut.squeeze(1)\n",
    "        ], dim=-1)\n",
    "        \n",
    "\n",
    "        logits = self.classifier(self.dropout(self.tanh(self.linear_intermediate(combined_embedding))))\n",
    "        return logits\n",
    "\n",
    "\n",
    "MODEL_NAME = \"pysentimiento/robertuito-sentiment-analysis\"\n",
    "model = SentimentClassifierWithMultiAttention(MODEL_NAME, num_labels=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congelamos todas las capas menos la última capa de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for param in list(model.bert.parameters()):\n",
    "#    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentClassifierWithMultiAttention(\n",
       "  (bert): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(30002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(130, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (attention_positive): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (attention_negative): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (attention_neutral): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (linear_intermediate): Linear(in_features=3072, out_features=768, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=data_collator)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=data_collator)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning Context Awareness Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1265\n"
     ]
    }
   ],
   "source": [
    "models_path = \"../checkpoints/\"\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "num_epochs = 5\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 253/1265 [23:26<1:13:54,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Train Loss: 0.9950, Val Loss: 0.9903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 506/1265 [48:37<48:37,  3.84s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Train Loss: 0.8278, Val Loss: 1.0296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 759/1265 [1:17:02<32:59,  3.91s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Train Loss: 0.6310, Val Loss: 1.1815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1012/1265 [1:43:30<17:05,  4.05s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Train Loss: 0.4221, Val Loss: 1.5789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1265/1265 [2:09:05<00:00,  4.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train Loss: 0.2629, Val Loss: 1.7765\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "lfunct = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0 \n",
    "    num_train_batches = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)  # Logits\n",
    "        y_true = batch[\"labels\"]\n",
    "        \n",
    "        loss = lfunct(outputs, y_true)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        epoch_train_loss += loss.item()\n",
    "        num_train_batches += 1\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Compute average training loss for the epoch\n",
    "    avg_train_loss = epoch_train_loss / num_train_batches\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Run validation\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    num_val_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            y_true = batch[\"labels\"]\n",
    "\n",
    "            loss = lfunct(outputs, y_true)\n",
    "            epoch_val_loss += loss.item()\n",
    "            num_val_batches += 1\n",
    "\n",
    "    avg_val_loss = epoch_val_loss / num_val_batches\n",
    "    val_losses.append(avg_val_loss)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Save model\n",
    "    # model.save_pretrained(models_path + f\"epoch_{epoch + 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot Training vs Validation Loss\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_losses, label=\"Training Loss\", color=\"blue\", alpha=0.7)\n",
    "plt.plot(val_losses, label=\"Validation Loss\", color=\"red\", alpha=0.7)\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"../checkpoints/context.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, \"../checkpoints/full_context_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(577,) (577,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.57      0.59      0.58       196\n",
      "         NEU       0.70      0.67      0.69       318\n",
      "         POS       0.31      0.35      0.33        63\n",
      "\n",
      "    accuracy                           0.61       577\n",
      "   macro avg       0.53      0.54      0.53       577\n",
      "weighted avg       0.62      0.61      0.61       577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "\n",
    "y_pred_val = []\n",
    "y_true_val = []\n",
    "with torch.no_grad(): \n",
    "    for batch in val_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        y_pred_val.extend(torch.argmax(outputs, dim=-1).tolist())\n",
    "        y_true_val.extend(batch[\"labels\"].tolist())\n",
    "\n",
    "y_pred_val = np.array(y_pred_val)\n",
    "y_true_val = np.array(y_true_val)\n",
    "print(y_pred_val.shape, y_true_val.shape)\n",
    "print(classification_report(y_true_val, y_pred_val, target_names=mapping.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1153,) (1153,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.56      0.59      0.57       392\n",
      "         NEU       0.69      0.64      0.66       634\n",
      "         POS       0.32      0.37      0.35       127\n",
      "\n",
      "    accuracy                           0.59      1153\n",
      "   macro avg       0.52      0.53      0.53      1153\n",
      "weighted avg       0.60      0.59      0.60      1153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "\n",
    "y_pred_val = []\n",
    "y_true_val = []\n",
    "with torch.no_grad(): \n",
    "    for batch in test_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        y_pred_val.extend(torch.argmax(outputs, dim=-1).tolist())\n",
    "        y_true_val.extend(batch[\"labels\"].tolist())\n",
    "\n",
    "y_pred_val = np.array(y_pred_val)\n",
    "y_true_val = np.array(y_true_val)\n",
    "print(y_pred_val.shape, y_true_val.shape)\n",
    "print(classification_report(y_true_val, y_pred_val, target_names=mapping.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
