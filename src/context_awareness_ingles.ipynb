{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pepe/miniconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import warnings\n",
    "import random\n",
    "import ast\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_DIM = 256\n",
    "PROB = 0.3\n",
    "DROPOUT = 0.2  # Esto\n",
    "EMBED_DIM = 768\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-5\n",
    "WD = 1e-2\n",
    "EPOCHS = 10\n",
    "ACTIVATION = nn.GELU()\n",
    "DATA_AUG = True  # Esto\n",
    "\n",
    "language = \"ENG\"\n",
    "\n",
    "if language == \"ENG\":\n",
    "    MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "    text_col = \"translation\" \n",
    "    emb_col = \"embeddings_ingles\" \n",
    "    par_col = \"paraphrase\" \n",
    "    par_emb_col_1 = \"embedding_paraphrase1\" \n",
    "    par_emb_col_2 = \"embedding_paraphrase2\" \n",
    "    TOKEN_DIM = TOKEN_DIM\n",
    "\n",
    "else: \n",
    "    MODEL_NAME = \"pysentimiento/robertuito-sentiment-analysis\"\n",
    "    text_col = \"post content\"\n",
    "    emb_col = \"embeddings\"\n",
    "    par_col = \"paraphrase_esp\"\n",
    "    par_emb_col_1 = \"embedding_paraphrase_esp1\"\n",
    "    par_emb_col_2 = \"embedding_paraphrase_esp2\"\n",
    "    TOKEN_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path_to_dataset):\n",
    "    return pd.read_csv(path_to_dataset)\n",
    "\n",
    "def extract_similar_descriptions(e, embeddings, k):\n",
    "    similarities = cosine_similarity([e], embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[-k:][::-1]\n",
    "    return top_indices\n",
    "    \n",
    "def compute_embeddings_distance(embedding_str, k, df):\n",
    "    # QUitamos del dataset la misma fila con la que estamos trabajando\n",
    "    df = df[df[emb_col]!= embedding_str]\n",
    "\n",
    "    def parse_embedding(embedding_str):\n",
    "        embedding_str = embedding_str.strip(\"[]\")\n",
    "        return np.array(embedding_str.split(), dtype=np.float32)\n",
    "    \n",
    "    embedding = parse_embedding(embedding_str)\n",
    "    df[emb_col] = df[emb_col].apply(lambda x: parse_embedding(x))\n",
    "\n",
    "    df_pos = df[df[\"label\"]==2]\n",
    "    df_neu = df[df[\"label\"]==1]\n",
    "    df_neg = df[df[\"label\"]==0]\n",
    "\n",
    "    pos_description_embeddings = np.vstack(df_pos[emb_col].values)\n",
    "    pos_nearest_descriptions = extract_similar_descriptions(embedding, pos_description_embeddings, k)\n",
    "    pos_result = df_pos.iloc[pos_nearest_descriptions][text_col]\n",
    "\n",
    "    neu_description_embeddings = np.vstack(df_neu[emb_col].values)\n",
    "    neu_nearest_descriptions = extract_similar_descriptions(embedding, neu_description_embeddings, k)\n",
    "    neu_result = df_neu.iloc[neu_nearest_descriptions][text_col]\n",
    "\n",
    "    neg_description_embeddings = np.vstack(df_neg[emb_col].values)\n",
    "    neg_nearest_descriptions = extract_similar_descriptions(embedding, neg_description_embeddings, k)\n",
    "    neg_result = df_neg.iloc[neg_nearest_descriptions][text_col]\n",
    "    \n",
    "\n",
    "    return pos_result.to_list(), neu_result.to_list(), neg_result.to_list()\n",
    "\n",
    "mapping = {\"NEG\":0, \"NEU\":1, \"POS\":2}\n",
    "\n",
    "reverse_mapping = {0:\"NEG\", 1: \"NEU\", 2:\"POS\"}\n",
    "\n",
    "def label2int(label):\n",
    "    return mapping[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device count: 1\n",
      "Current device: 0\n",
      "NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device count:\", torch.cuda.device_count())\n",
    "    print(\"Current device:\", torch.cuda.current_device())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"../data/data.csv\")\n",
    "task_1 = load_dataset(\"../data/augmented_dataset_task1.csv\")\n",
    "task_2 = load_dataset(\"../data/augmented_dataset_task2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = load_dataset(\"../data/train_paraphrased.csv\")\n",
    "# test_df = load_dataset(\"../data/test_paraphrased.csv\")\n",
    "# val_df = load_dataset(\"../data/val_paraphrased.csv\")\n",
    "# dev_df = load_dataset(\"../data/dev_paraphrased.csv\")\n",
    "# train_df = pd.concat([train_df, dev_df]).reset_index()\n",
    "\n",
    "train_df, test_df = train_test_split(data, test_size=0.2, random_state=RANDOM_SEED, stratify=data['label'])\n",
    "# train_df, val_df = train_test_split(train_df, test_size=1/8, random_state=RANDOM_SEED, stratify=train_df['label'])\n",
    "\n",
    "# Copy test_df to val_df\n",
    "val_df = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_1[\"label\"]=0\n",
    "task_2[\"label\"]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([0.9870, 0.5916, 3.3713], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, paraphrases, labels, tokenizer, k, df, type = None, augmentation = False, local_database = train_df):\n",
    "        super().__init__() \n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.k = k\n",
    "        self.df = df\n",
    "        self.local_database = local_database\n",
    "        self.paraphrases = paraphrases\n",
    "        self.type = type\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # DATA AUG\n",
    "        if self.type == \"train\" and self.augmentation:\n",
    "            paraphrase = self.paraphrases[idx]\n",
    "            samples = ast.literal_eval(paraphrase)\n",
    "            samples=list(samples)\n",
    "            samples.append(text)\n",
    "            text = random.choice(samples)\n",
    "            index = samples.index(text)\n",
    "\n",
    "\n",
    "            if index == 0:\n",
    "                embedding_str = self.df.loc[self.df[par_col] == paraphrase, par_emb_col_1].values[0]\n",
    "            elif index == 1:\n",
    "                embedding_str = self.df.loc[self.df[par_col] == paraphrase, par_emb_col_2].values[0]\n",
    "            else: \n",
    "                embedding_str = self.df.loc[self.df[text_col] == text, emb_col].values[0]\n",
    "\n",
    "            words = text.split()\n",
    "            if random.random() < PROB:\n",
    "            \n",
    "                if len(words) > 1:\n",
    "                    num_to_remove = max(1, int(0.1 * len(words)))  # Quitar ~10% de las palabras\n",
    "                    indices_to_remove = random.sample(range(len(words)), num_to_remove)\n",
    "                    words = [w for i, w in enumerate(words) if i not in indices_to_remove]\n",
    "                    text = \" \".join(words)\n",
    "\n",
    "                if random.random() < PROB:\n",
    "\n",
    "                    if len(words) > 1:\n",
    "                        random.shuffle(words)\n",
    "                        text = \" \".join(words)\n",
    "\n",
    "        else:\n",
    "            embedding_str = embedding_str = self.df.loc[self.df[text_col] == text, emb_col].values[0]\n",
    "        \n",
    "        # Obtener los textos más similares por clase\n",
    "        pos_texts, neu_texts, neg_texts = compute_embeddings_distance(embedding_str, self.k, self.local_database)\n",
    "        # Tokenizar el texto principal\n",
    "        encoding = self.tokenizer(text, padding=\"max_length\", truncation=True, max_length=TOKEN_DIM, return_tensors=\"pt\")\n",
    "\n",
    "        # Tokenizar los textos más similares\n",
    "        pos_tokens = self.tokenizer(pos_texts, padding=\"max_length\", truncation=True, max_length=TOKEN_DIM, return_tensors=\"pt\")\n",
    "        neu_tokens = self.tokenizer(neu_texts, padding=\"max_length\", truncation=True, max_length=TOKEN_DIM, return_tensors=\"pt\")\n",
    "        neg_tokens = self.tokenizer(neg_texts, padding=\"max_length\", truncation=True, max_length=TOKEN_DIM, return_tensors=\"pt\")\n",
    "        \n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "            \"pos_tokens\": pos_tokens[\"input_ids\"],\n",
    "            \"neu_tokens\": neu_tokens[\"input_ids\"],\n",
    "            \"neg_tokens\": neg_tokens[\"input_ids\"],\n",
    "            \"pos_attention\": pos_tokens[\"attention_mask\"],\n",
    "            \"neu_attention\": neu_tokens[\"attention_mask\"],\n",
    "            \"neg_attention\": neg_tokens[\"attention_mask\"],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "train_dataset = SentimentDataset(\n",
    "    texts=train_df[text_col].tolist(),\n",
    "    labels=train_df[\"label\"].tolist(),\n",
    "    paraphrases=train_df[par_col].tolist(),\n",
    "    tokenizer=tokenizer,\n",
    "    k=1,  # Número de mensajes similares a recuperar\n",
    "    df = train_df,\n",
    "    type = \"train\",\n",
    "    augmentation=DATA_AUG\n",
    ")\n",
    "\n",
    "val_dataset = SentimentDataset(\n",
    "    texts=val_df[text_col].tolist(),\n",
    "    labels=val_df[\"label\"].tolist(),\n",
    "    paraphrases = [],\n",
    "    tokenizer=tokenizer,\n",
    "    k=1,  # Número de mensajes similares a recuperar\n",
    "    df = val_df\n",
    ")\n",
    "\n",
    "test_dataset = SentimentDataset(\n",
    "    texts=test_df[text_col].tolist(),\n",
    "    labels=test_df[\"label\"].tolist(),\n",
    "    paraphrases = [],\n",
    "    tokenizer=tokenizer,\n",
    "    k=1,  # Número de mensajes similares a recuperar\n",
    "    df = test_df\n",
    ")\n",
    "\n",
    "task_1_dataset = SentimentDataset(\n",
    "    texts=task_1[text_col].tolist(),\n",
    "    labels=task_1[\"label\"].tolist(),\n",
    "    paraphrases = [],\n",
    "    tokenizer=tokenizer,\n",
    "    k=1,  # Número de mensajes similares a recuperar\n",
    "    df = task_1\n",
    ")\n",
    "\n",
    "task_2_dataset = SentimentDataset(\n",
    "    texts=task_2[text_col].tolist(),\n",
    "    labels=task_2[\"label\"].tolist(),\n",
    "    paraphrases = [],\n",
    "    tokenizer=tokenizer,\n",
    "    k=1,  # Número de mensajes similares a recuperar\n",
    "    df = task_2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "Text: Demisexuality, from the English suffix demi-, \"half,\" and the Latin sexus \"sex,\" is a term coined by the Asexual Visibility and Education Network (AVEN) to refer to sexual attraction exclusively towards individuals with whom strong, stable, and/or lasting emotional bonds have been developed previously. Before that, a demisexual may behave like an 'asexual' and may even identify as such. Furthermore, demisexuality can refer to any type of fixation that develops into a secondary sexual attraction towards individuals with whom strong love bonds have been built, while primary sexual attraction manifests as an apparent 'asexual' orientation.\n",
      "Label: 0\n",
      "Input IDs: tensor([    0, 24658, 45799,  1571,     6,    31,     5,  2370, 47503,  4410,\n",
      "          118, 20551,    22,  4809,    60,     8,     5,  5862,  2099,   687,\n",
      "           22,  8821,    60,    16,    10,  1385, 32993,    30,     5,    83,\n",
      "        28744, 10035, 12203,     8,  3061,  3658,    36, 10612,  2796,    43,\n",
      "            7,  9115,     7,  1363, 13003,  8992,  1567,  2172,    19,  2661,\n",
      "          670,     6,  4375,     6,     8,    73,   368,  9735,  3722,  3554,\n",
      "           33,    57,  2226,  1433,     4,  3224,    14,     6,    10,  4410,\n",
      "        45799,   189, 18871,   101,    41,   128,  3175, 47830,   108,     8,\n",
      "          189,   190,  3058,    25,   215,     4,  9870,     6,  4410, 45799,\n",
      "         1571,    64,  9115,     7,   143,  1907,     9, 42004,    14, 12626,\n",
      "           88,    10,  5929,  1363, 13003,  1567,  2172,    19,  2661,   670,\n",
      "          657,  3554,    33,    57,  1490,     6,   150,  2270,  1363, 13003,\n",
      "        41958,    25,    41,  5890,   128,  3175, 47830,   108, 14497,     4,\n",
      "            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Positives: tensor([[    0, 24792, 41746,  1571,   117, 26613,    32,   716,    15,   171,\n",
      "          2433,     8,  2128,  6723,    15,     5,    86,     8,     5,  4566,\n",
      "             8,  4106,  5377,    11,    61,    51,  2179,     8,   939,   206,\n",
      "            47,  1266,  3959, 44153,  7228,    61,    16,    10,   182,  6336,\n",
      "          5674,   939,   386,    31,     5, 18884, 27074,     9, 34655,  2166,\n",
      "             8, 27499,  2400,     8, 35195,    49, 14082,     7,  2313,    89,\n",
      "            32,  6214,    54,    32,    55,  5616,     7,  2313,    87,     5,\n",
      "           144, 20399,   139,  4334,  1644,  2128,    63,   357,     7,   342,\n",
      "          4157,  4364,     2,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1]])\n",
      "Neutral: tensor([[    0,   405,    16,    10,  8576,  4420,    13,   171,    55,  2188,\n",
      "            87,    47,  4521,    53,  3284,     5,  1353,  6659,     9,    10,\n",
      "         28744,  1571,    16,     5,   169,  1363, 13003,    16,  2984, 50118,\n",
      "         50118, 28744, 13003,    16,  6238,    25,     5,  3722,  1263,  2984,\n",
      "            77, 27515,   103,  6909,  2099,  2868,    14,    47,   101,    61,\n",
      "           818,   460, 11570,  6568,    10,  4724,     7,    33,  2099,    19,\n",
      "            14,  1989,   621,    11,   765,    63,  6923,     7,    33,  2099,\n",
      "            19,   951,  4010,    66,     9,  4724,    10, 28744,    82,   109,\n",
      "            45,   676,    42,    50,   182,   410,    50, 10930,    50,  6122,\n",
      "            15, 22438,  2433,    41,   505,   233,     9,     5,  8576,    67,\n",
      "          1171,  4410, 45799,    29,    54,    32,  4453,     9,  7242,   129,\n",
      "          5929, 12528,  1363, 13003,  5929, 12528, 13003,    16,    65,    14,\n",
      "          1411,  1684,    99,    16,  9568,    11,     5,    78,   360,     9,\n",
      "           529,   951,    24,    16,    45,     5,  2166,  2772,     5,  2236,\n",
      "            50,     5,   809,  2777,    24,    34,    55,     7,   109,    19,\n",
      "             5,  5151, 15052, 22894, 16275,    49,   317,    11,     5,   232,\n",
      "             8,     5,  2175,    14,    16,  4829,   951,    54,    16,  4410,\n",
      "         45799,   189,    28,    10, 28744,    13,  3544,   107,   137, 12748,\n",
      "            10,   670,   615,  2175,    19,   951,     7,   676,  5929, 12528,\n",
      "         13003, 50118, 50118,  1115,  2013,    31,    14,    89,    32,   171,\n",
      "           650,  5894,   101,   167,    54,    33,  2099,    13, 10483,    13,\n",
      "          1759, 39025,    50, 17672,  1413,  1782,   143, 20745,    50,    32,\n",
      "           129,  7671,     7, 31053,  6086,    50,  2788,    70,     9,    14,\n",
      "            16,    55,    59,     5,   169, 17969,    16,  2984,     8,  1712,\n",
      "          1687,    11,  5177, 31479,  2507,    51,    32,    45,     5,  1353,\n",
      "          6659,     9,    10, 28744,  1571,     2]])\n",
      "Negatives: tensor([[    0,  3056,  4420,    82,   356,   159,    15,   167,    54, 33976,\n",
      "           236,     7,    33,  2099,    70,     5,    86,   101,   144,   109,\n",
      "             8,    63,   182,  1537,    13,  1246,     7,   304, 33799,    25,\n",
      "            41, 18566,    24,  2594,    19,  1337,   383,    67,    19,  3766,\n",
      "           114,    47, 33976,  4076,   171,    82,   356,   159,    15,    47,\n",
      "         50118, 50118,   463,  4420,   939,  2854,    14,    24,  1411,   136,\n",
      "             5, 21668,     9, 26385,    53,    11,    14,   403,   145,  5100,\n",
      "            74,    67,   213,   136,    14,   648,    24,  1302,     7,    28,\n",
      "            55,  3903,    87,   145,    10, 28744,     2,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1]])\n",
      "Positives: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "Neutral: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "Negatives: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    sample = task_1_dataset[i]\n",
    "    print(f\"Sample {i + 1}:\")\n",
    "    print(f\"Text: {task_1_dataset.texts[i]}\")\n",
    "    print(f\"Label: {sample['labels'].item()}\")\n",
    "    print(f\"Input IDs: {sample['input_ids']}\")\n",
    "    print(f\"Attention Mask: {sample['attention_mask']}\")\n",
    "    print(f\"Positives: {sample['pos_tokens']}\")\n",
    "    print(f\"Neutral: {sample['neu_tokens']}\")\n",
    "    print(f\"Negatives: {sample['neg_tokens']}\")\n",
    "    print(f\"Positives: {sample['pos_attention']}\")\n",
    "    print(f\"Neutral: {sample['neu_attention']}\")\n",
    "    print(f\"Negatives: {sample['neg_attention']}\")\n",
    "    print(\"\\n\" + \"-\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
    "    # Compute the dot products between Q and K, then scale by the square root of the key dimension\n",
    "    d_k = Q.size(-1)\n",
    "    scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
    "\n",
    "    # Apply mask if provided (useful for masked self-attention in transformers)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "    # Softmax to normalize scores, producing attention weights\n",
    "    attention_weights = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    # Compute the final output as weighted values\n",
    "    output = torch.matmul(attention_weights, V)\n",
    "    return output, attention_weights\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        # Define linear transformations for Q, K, V\n",
    "        self.query = nn.Linear(embed_size, embed_size)\n",
    "        self.key = nn.Linear(embed_size, embed_size)\n",
    "        self.value = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        # Generate Q, K, V matrices\n",
    "        Q = self.query(q)\n",
    "        K = self.key(k)\n",
    "        V = self.value(v)\n",
    "        \n",
    "        # Calculate attention using our scaled dot-product function\n",
    "        out, _ = scaled_dot_product_attention(Q, K, V)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifierWithMultiAttention(nn.Module):\n",
    "    def __init__(self, base_model_name, num_labels=3, num_heads=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = AutoModel.from_pretrained(base_model_name)\n",
    "\n",
    "        \"\"\"self.attention_positive = SelfAttention(EMBED_DIM)\n",
    "        self.attention_negative = SelfAttention(EMBED_DIM)\n",
    "        self.attention_neutral = SelfAttention(EMBED_DIM)\"\"\"\n",
    "\n",
    "        self.attention_positive = nn.MultiheadAttention(embed_dim=EMBED_DIM, num_heads=num_heads, batch_first=True)\n",
    "        self.attention_negative = nn.MultiheadAttention(embed_dim=EMBED_DIM, num_heads=num_heads, batch_first=True)\n",
    "        self.attention_neutral = nn.MultiheadAttention(embed_dim=EMBED_DIM, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "\n",
    "        \"\"\"self.linear_intermediate = nn.Linear(EMBED_DIM * 4, EMBED_DIM)\n",
    "        self.activation = ACTIVATION\n",
    "        self.dropout = nn.Dropout(DROPOUT)\n",
    "        self.classifier = nn.Linear(EMBED_DIM, num_labels)\"\"\"\n",
    "\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(EMBED_DIM * 4, EMBED_DIM),\n",
    "            ACTIVATION,\n",
    "            nn.Dropout(DROPOUT),\n",
    "            nn.Linear(EMBED_DIM, EMBED_DIM // 2),\n",
    "            ACTIVATION,\n",
    "            nn.Dropout(DROPOUT),\n",
    "            nn.Linear(EMBED_DIM // 2, EMBED_DIM // 4),\n",
    "            ACTIVATION,\n",
    "            nn.Dropout(DROPOUT)\n",
    "        )\n",
    "        self.classifier = nn.Linear(EMBED_DIM // 4, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None, pos_tokens=None, neu_tokens=None, neg_tokens=None, pos_attention=None, neu_attention = None, neg_attention = None):\n",
    "        \n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]  # Token CLS\n",
    "        cls_embedding_expanded = cls_embedding.unsqueeze(1)\n",
    "\n",
    "        pos_outputs_0 = self.bert(pos_tokens[:,0,:], attention_mask=pos_attention[:,0,:])\n",
    "        pos_cls_embedding_0 = pos_outputs_0.last_hidden_state[:, 0, :]\n",
    "        pos_cls_embedding_0 = pos_cls_embedding_0.unsqueeze(1)  \n",
    "\n",
    "        pos_cls_embedding = pos_cls_embedding_0\n",
    "\n",
    "        neu_outputs_0 = self.bert(neu_tokens[:,0,:], attention_mask=neu_attention[:,0,:])\n",
    "        neu_cls_embedding_0 = neu_outputs_0.last_hidden_state[:, 0, :]\n",
    "        neu_cls_embedding_0 = neu_cls_embedding_0.unsqueeze(1)  \n",
    "\n",
    "        neu_cls_embedding = neu_cls_embedding_0\n",
    "\n",
    "        neg_outputs_0 = self.bert(neg_tokens[:,0,:], attention_mask=neg_attention[:,0,:])\n",
    "        neg_cls_embedding_0 = neg_outputs_0.last_hidden_state[:, 0, :]\n",
    "        neg_cls_embedding_0 = neg_cls_embedding_0.unsqueeze(1)  \n",
    "\n",
    "        neg_cls_embedding = neg_cls_embedding_0\n",
    "\n",
    "        cls_embedding_expanded = cls_embedding_expanded.float()\n",
    "        pos_cls_embedding = pos_cls_embedding.float()\n",
    "        neg_cls_embedding = neg_cls_embedding.float()\n",
    "        neu_cls_embedding = neu_cls_embedding.float()\n",
    "\n",
    "        \n",
    "        \"\"\"\n",
    "        Cada salida (attn_pos, attn_neg, attn_neut) representa una versión contextualizada del cls_embedding \n",
    "        influenciada por los mensajes de su respectiva clase. Es decir, el embedding [CLS] de entrada ha sido \n",
    "        modificado en función de lo que \"aprendió\" al atender a los mensajes positivos, negativos o neutros.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"attn_pos = self.attention_positive(cls_embedding_expanded, pos_cls_embedding, cls_embedding_expanded)\n",
    "        attn_neg = self.attention_negative(cls_embedding_expanded, neg_cls_embedding, cls_embedding_expanded)\n",
    "        attn_neut = self.attention_neutral(cls_embedding_expanded, neu_cls_embedding, cls_embedding_expanded)\"\"\"\n",
    "\n",
    "        attn_pos, _ = self.attention_positive(cls_embedding_expanded, pos_cls_embedding, cls_embedding_expanded)\n",
    "        attn_neg, _ = self.attention_negative(cls_embedding_expanded, neg_cls_embedding, cls_embedding_expanded)\n",
    "        attn_neut, _ = self.attention_neutral(cls_embedding_expanded, neu_cls_embedding, cls_embedding_expanded)\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        En este punto hemos sacado un nuevo embedding aplicando la capa de atencion del embedding entrante con los dos embeddings de cada clase siendo:\n",
    "        Q = embedding entrante\n",
    "        K = clase_emb\n",
    "        V = embedding entrante\n",
    "\n",
    "        Porque si V = clase_emb entonces:\n",
    "        Si pasas clase_emb como V, entonces el mecanismo de atención devolverá una combinación ponderada de los embeddings de la clase POSITIVA, \n",
    "        determinada por la similitud entre cls_embedding_expanded (Q) y clase_emb (K).\n",
    "        \"\"\"\n",
    "\n",
    "        combined_embedding = torch.cat([\n",
    "            cls_embedding,\n",
    "            attn_pos.squeeze(1),\n",
    "            attn_neg.squeeze(1),\n",
    "            attn_neut.squeeze(1)\n",
    "        ], dim=-1)\n",
    "        \n",
    "\n",
    "        #logits = self.classifier(self.dropout(self.activation(self.linear_intermediate(combined_embedding))))\n",
    "        logits = self.classifier(self.feedforward(combined_embedding))\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "model = SentimentClassifierWithMultiAttention(MODEL_NAME, num_labels=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congelamos todas las capas menos la última capa de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in list(model.bert.parameters()):\n",
    "#    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentClassifierWithMultiAttention(\n",
       "  (bert): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (attention_positive): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (attention_negative): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (attention_neutral): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (feedforward): Sequential(\n",
       "    (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=768, out_features=384, bias=True)\n",
       "    (4): GELU(approximate='none')\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=384, out_features=192, bias=True)\n",
       "    (7): GELU(approximate='none')\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (classifier): Linear(in_features=192, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=data_collator)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=data_collator)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "task_1_dataloader = DataLoader(task_1_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=data_collator)\n",
    "task_2_dataloader = DataLoader(task_2_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([16, 256]),\n",
       " 'attention_mask': torch.Size([16, 256]),\n",
       " 'labels': torch.Size([16]),\n",
       " 'pos_tokens': torch.Size([16, 1, 256]),\n",
       " 'neu_tokens': torch.Size([16, 1, 256]),\n",
       " 'neg_tokens': torch.Size([16, 1, 256]),\n",
       " 'pos_attention': torch.Size([16, 1, 256]),\n",
       " 'neu_attention': torch.Size([16, 1, 256]),\n",
       " 'neg_attention': torch.Size([16, 1, 256])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for batch in task_1_dataloader:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning Context Awareness Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3610\n"
     ]
    }
   ],
   "source": [
    "models_path = \"../checkpoints/\"\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=WD) #, weight_decay=WD\n",
    "\n",
    "num_epochs = EPOCHS\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[8], gamma=0.1)\n",
    "\n",
    "\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 361/3610 [33:38<4:01:30,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10         Train Loss: 1.0331     Val Loss: 0.9585     Macro F1: 0.4751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 722/3610 [1:16:05<3:41:49,  4.61s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10         Train Loss: 0.9355     Val Loss: 0.9616     Macro F1: 0.4432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1083/3610 [1:58:41<3:12:40,  4.57s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10         Train Loss: 0.8684     Val Loss: 0.9892     Macro F1: 0.4949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 1444/3610 [2:41:15<2:45:09,  4.58s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10         Train Loss: 0.7990     Val Loss: 0.9171     Macro F1: 0.5543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1805/3610 [3:23:50<2:17:27,  4.57s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10         Train Loss: 0.7316     Val Loss: 1.0224     Macro F1: 0.5490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 2166/3610 [4:06:24<1:49:58,  4.57s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10         Train Loss: 0.7001     Val Loss: 0.9453     Macro F1: 0.5272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 2527/3610 [4:48:58<1:22:16,  4.56s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10         Train Loss: 0.6250     Val Loss: 1.1359     Macro F1: 0.5415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 2888/3610 [5:31:31<54:58,  4.57s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10         Train Loss: 0.5786     Val Loss: 1.0250     Macro F1: 0.5057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 3249/3610 [6:14:05<27:29,  4.57s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10         Train Loss: 0.5473     Val Loss: 1.2021     Macro F1: 0.5310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3610/3610 [6:56:39<00:00,  4.62s/it]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10         Train Loss: 0.5004     Val Loss: 1.3653     Macro F1: 0.5509\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "lfunct = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0 \n",
    "    num_train_batches = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        outputs = model(**batch)  # Logits\n",
    "        y_true = batch[\"labels\"]\n",
    "        \n",
    "        loss = lfunct(outputs, y_true)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        epoch_train_loss += loss.item()\n",
    "        num_train_batches += 1\n",
    "\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Compute average training loss for the epoch\n",
    "    avg_train_loss = epoch_train_loss / num_train_batches\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Run validation\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    num_val_batches = 0\n",
    "\n",
    "    y_preds_val = []\n",
    "    y_trues_val = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            y_true = batch[\"labels\"]\n",
    "\n",
    "            loss = lfunct(outputs, y_true)\n",
    "            epoch_val_loss += loss.item()\n",
    "            num_val_batches += 1\n",
    "\n",
    "            y_preds_val.extend(torch.argmax(outputs, dim=-1).cpu().tolist())\n",
    "            y_trues_val.extend(batch[\"labels\"].cpu().tolist())\n",
    "\n",
    "    y_preds_val = np.array(y_preds_val)\n",
    "    y_trues_val = np.array(y_trues_val)\n",
    "    f1_val = f1_score(y_trues_val, y_preds_val, average='macro')\n",
    "\n",
    "    avg_val_loss = epoch_val_loss / num_val_batches\n",
    "    val_losses.append(avg_val_loss)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs:<10} Train Loss: {avg_train_loss:<10.4f} Val Loss: {avg_val_loss:<10.4f} Macro F1: {f1_val:.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"../checkpoints/{epoch + 1}_context.pth\")\n",
    "    #torch.save(model, f\"../checkpoints/{epoch + 1}_full_context_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot Training vs Validation Loss\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_losses, label=\"Training Loss\", color=\"blue\", alpha=0.7)\n",
    "plt.plot(val_losses, label=\"Validation Loss\", color=\"red\", alpha=0.7)\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"../checkpoints/context.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, \"../checkpoints/full_context_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentClassifierWithMultiAttention(\n",
       "  (bert): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (attention_positive): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (attention_negative): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (attention_neutral): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "  )\n",
       "  (feedforward): Sequential(\n",
       "    (0): Linear(in_features=3072, out_features=768, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=768, out_features=384, bias=True)\n",
       "    (4): GELU(approximate='none')\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=384, out_features=192, bias=True)\n",
       "    (7): GELU(approximate='none')\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (classifier): Linear(in_features=192, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\"../checkpoints/4_context.pth\", map_location=torch.device(device)) \n",
    "model = SentimentClassifierWithMultiAttention(MODEL_NAME, num_labels=3)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1442,) (1442,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.56      0.59      0.57       487\n",
      "         NEU       0.70      0.67      0.68       812\n",
      "         POS       0.39      0.41      0.40       143\n",
      "\n",
      "    accuracy                           0.62      1442\n",
      "   macro avg       0.55      0.56      0.55      1442\n",
      "weighted avg       0.62      0.62      0.62      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "y_pred_val = []\n",
    "y_true_val = []\n",
    "with torch.no_grad(): \n",
    "    for batch in val_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        y_pred_val.extend(torch.argmax(outputs, dim=-1).tolist())\n",
    "        y_true_val.extend(batch[\"labels\"].tolist())\n",
    "\n",
    "y_pred_val = np.array(y_pred_val)\n",
    "y_true_val = np.array(y_true_val)\n",
    "print(y_pred_val.shape, y_true_val.shape)\n",
    "print(classification_report(y_true_val, y_pred_val, target_names=mapping.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1442,) (1442,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.56      0.59      0.57       487\n",
      "         NEU       0.70      0.67      0.68       812\n",
      "         POS       0.39      0.41      0.40       143\n",
      "\n",
      "    accuracy                           0.62      1442\n",
      "   macro avg       0.55      0.56      0.55      1442\n",
      "weighted avg       0.62      0.62      0.62      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "y_pred_test = []\n",
    "y_true_test = []\n",
    "with torch.no_grad(): \n",
    "    for batch in test_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        y_pred_test.extend(torch.argmax(outputs, dim=-1).tolist())\n",
    "        y_true_test.extend(batch[\"labels\"].tolist())\n",
    "\n",
    "y_pred_test = np.array(y_pred_test)\n",
    "y_true_test = np.array(y_true_test)\n",
    "print(y_pred_test.shape, y_true_test.shape)\n",
    "print(classification_report(y_true_test, y_pred_test, target_names=mapping.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "y_pred_task_1 = []\n",
    "with torch.no_grad(): \n",
    "    for batch in task_1_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        y_pred_task_1.extend(torch.argmax(outputs, dim=-1).tolist())\n",
    "\n",
    "y_pred_task_1 = np.array(y_pred_task_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = load_dataset(\"../data/translated_dataset_task1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = aux[\"id\"]\n",
    "\n",
    "preds_task_1 = pd.DataFrame(columns=[\"id\", \"label\"])\n",
    "preds_task_1[\"id\"] = ids\n",
    "preds_task_1[\"label\"]= y_pred_task_1\n",
    "preds_task_1[\"label\"] = preds_task_1[\"label\"].apply(lambda x: reverse_mapping[x])\n",
    "preds_task_1.to_csv(\"../data/task1_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "y_pred_task_2 = []\n",
    "with torch.no_grad(): \n",
    "    for batch in task_2_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        y_pred_task_2.extend(torch.argmax(outputs, dim=-1).tolist())\n",
    "\n",
    "y_pred_task_2 = np.array(y_pred_task_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = load_dataset(\"../data/translated_dataset_task2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = aux[\"id\"]\n",
    "\n",
    "preds_task_2 = pd.DataFrame(columns=[\"id\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_task_2[\"id\"] = ids\n",
    "preds_task_2[\"label\"]= y_pred_task_2\n",
    "preds_task_2[\"label\"] = preds_task_2[\"label\"].apply(lambda x: reverse_mapping[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_task_2.to_csv(\"../data/task2_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sample(model, tokenizer, sample_text, label, embedding_str):\n",
    "    \"\"\"\n",
    "    Predict the sentiment of a sample text\n",
    "    \"\"\"\n",
    "\n",
    "    pos_texts, neu_texts, neg_texts = compute_embeddings_distance(embedding_str, 1, train_df)\n",
    "    encoding = tokenizer(sample_text, padding=\"max_length\", truncation=True, max_length=TOKEN_DIM, return_tensors=\"pt\")\n",
    "\n",
    "    # Tokenizar los textos más similares\n",
    "    pos_tokens = tokenizer(pos_texts, padding=\"max_length\", truncation=True, max_length=TOKEN_DIM, return_tensors=\"pt\")\n",
    "    neu_tokens = tokenizer(neu_texts, padding=\"max_length\", truncation=True, max_length=TOKEN_DIM, return_tensors=\"pt\")\n",
    "    neg_tokens = tokenizer(neg_texts, padding=\"max_length\", truncation=True, max_length=TOKEN_DIM, return_tensors=\"pt\")\n",
    "    \n",
    "\n",
    "    inputs = {\n",
    "        \"input_ids\": encoding[\"input_ids\"],\n",
    "        \"attention_mask\": encoding[\"attention_mask\"],\n",
    "        \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        \"pos_tokens\": pos_tokens[\"input_ids\"].unsqueeze(1),\n",
    "        \"neu_tokens\": neu_tokens[\"input_ids\"].unsqueeze(1),\n",
    "        \"neg_tokens\": neg_tokens[\"input_ids\"].unsqueeze(1),\n",
    "        \"pos_attention\": pos_tokens[\"attention_mask\"].unsqueeze(1),\n",
    "        \"neu_attention\": neu_tokens[\"attention_mask\"].unsqueeze(1),\n",
    "        \"neg_attention\": neg_tokens[\"attention_mask\"].unsqueeze(1),\n",
    "    }\n",
    "    \n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs\n",
    "    probabilities = torch.softmax(logits, dim=-1)\n",
    "    \n",
    "    predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "    \n",
    "    \n",
    "    return predicted_class, probabilities[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = []\n",
    "y_true_test = []\n",
    "\n",
    "for i in range(len(test_df)):\n",
    "    input_text = test_df[\"translation\"][i]\n",
    "    input_label = test_df[\"label\"][i]\n",
    "    input_embedding = test_df[\"embeddings_ingles\"][i]    \n",
    "    # Get paraphrased samples\n",
    "    samples = ast.literal_eval(test_df[\"paraphrase\"][i])\n",
    "    samples=list(samples)\n",
    "    paraphrase_text1 = samples[0]\n",
    "    paraphrase_text2 = samples[1]\n",
    "    input_emb_p1 = test_df[\"embedding_paraphrase1\"][i]\n",
    "    input_emb_p2 = test_df[\"embedding_paraphrase2\"][i]\n",
    "\n",
    "    real_label = test_df['label'][i]\n",
    "\n",
    "    predicted_label, probabilities = predict_sample(model, tokenizer, input_text, input_label, input_embedding)\n",
    "    predicted_label1, probabilities1 = predict_sample(model, tokenizer, paraphrase_text1, input_label, input_emb_p1)\n",
    "    predicted_label2, probabilities2 = predict_sample(model, tokenizer, paraphrase_text2, input_label, input_emb_p2)\n",
    "\n",
    "    if predicted_label != predicted_label1 and predicted_label != predicted_label2 and predicted_label1 != predicted_label2:\n",
    "        labels = [predicted_label, predicted_label1, predicted_label2]\n",
    "        label1_score = max(probabilities)\n",
    "        label2_score = max(probabilities1)\n",
    "        label3_score = max(probabilities2)\n",
    "        scores = {label1_score: predicted_label, label2_score: predicted_label1, label3_score: predicted_label2}\n",
    "        final_label = max(scores.keys())\n",
    "        predicted_label = scores[final_label]\n",
    "    else:\n",
    "        # Get the most frequent label\n",
    "        predicted_label = max(predicted_label, predicted_label1, predicted_label2, key=[predicted_label, predicted_label1, predicted_label2].count)\n",
    "        \n",
    "    y_pred_test.append(predicted_label)\n",
    "    y_true_test.append(real_label)\n",
    "\n",
    "y_pred_test = np.array(y_pred_test)\n",
    "y_true_test = np.array(y_true_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.57      0.59      0.58       487\n",
      "         NEU       0.71      0.69      0.70       812\n",
      "         POS       0.41      0.41      0.41       143\n",
      "\n",
      "    accuracy                           0.63      1442\n",
      "   macro avg       0.56      0.56      0.56      1442\n",
      "weighted avg       0.63      0.63      0.63      1442\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7d1068f5fa90>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(y_true_test, y_pred_test, target_names=mapping.keys()))\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true_test, y_pred_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=mapping.values())\n",
    "disp.plot(cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m task_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtask_1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m task_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m task_1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "task_1[\"label\"] = task_1[\"label\"].apply(lambda x: mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ens_task_1 = []\n",
    "\n",
    "for i in range(len(task_1)):\n",
    "    input_text = task_1[\"translation\"][i]\n",
    "    input_label = task_1[\"label\"][i]\n",
    "    input_embedding = task_1[\"embeddings_ingles\"][i]    \n",
    "    # Get paraphrased samples\n",
    "    samples = ast.literal_eval(task_1[\"paraphrase\"][i])\n",
    "    samples=list(samples)\n",
    "    paraphrase_text1 = samples[0]\n",
    "    paraphrase_text2 = samples[1]\n",
    "    input_emb_p1 = task_1[\"embedding_paraphrase1\"][i]\n",
    "    input_emb_p2 = task_1[\"embedding_paraphrase2\"][i]\n",
    "\n",
    "\n",
    "    predicted_label, probabilities = predict_sample(model, tokenizer, input_text, input_label, input_embedding)\n",
    "    predicted_label1, probabilities1 = predict_sample(model, tokenizer, paraphrase_text1, input_label, input_emb_p1)\n",
    "    predicted_label2, probabilities2 = predict_sample(model, tokenizer, paraphrase_text2, input_label, input_emb_p2)\n",
    "\n",
    "    if predicted_label != predicted_label1 and predicted_label != predicted_label2 and predicted_label1 != predicted_label2:\n",
    "        labels = [predicted_label, predicted_label1, predicted_label2]\n",
    "        label1_score = max(probabilities)\n",
    "        label2_score = max(probabilities1)\n",
    "        label3_score = max(probabilities2)\n",
    "        scores = {label1_score: predicted_label, label2_score: predicted_label1, label3_score: predicted_label2}\n",
    "        final_label = max(scores.keys())\n",
    "        predicted_label = scores[final_label]\n",
    "    else:\n",
    "        # Get the most frequent label\n",
    "        predicted_label = max(predicted_label, predicted_label1, predicted_label2, key=[predicted_label, predicted_label1, predicted_label2].count)\n",
    "        \n",
    "    y_pred_ens_task_1.append(predicted_label)\n",
    "\n",
    "y_pred_ens_task_1 = np.array(y_pred_ens_task_1)\n",
    "\n",
    "aux = load_dataset(\"../data/translated_dataset_task1.csv\")\n",
    "\n",
    "ids = aux[\"id\"]\n",
    "\n",
    "preds_task_1_ens = pd.DataFrame(columns=[\"id\", \"label\"])\n",
    "preds_task_1_ens[\"id\"] = ids\n",
    "preds_task_1_ens[\"label\"]= y_pred_ens_task_1\n",
    "preds_task_1_ens[\"label\"] = preds_task_1_ens[\"label\"].apply(lambda x: reverse_mapping[x])\n",
    "preds_task_1_ens.to_csv(\"../data/task1_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2[\"label\"] = task_2[\"label\"].apply(lambda x: mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ens_task_2 = []\n",
    "\n",
    "for i in range(len(task_2)):\n",
    "    input_text = task_2[\"translation\"][i]\n",
    "    input_label = task_2[\"label\"][i]\n",
    "    input_embedding = task_2[\"embeddings_ingles\"][i]    \n",
    "    # Get paraphrased samples\n",
    "    samples = ast.literal_eval(task_2[\"paraphrase\"][i])\n",
    "    samples=list(samples)\n",
    "    paraphrase_text1 = samples[0]\n",
    "    paraphrase_text2 = samples[1]\n",
    "    input_emb_p1 = task_2[\"embedding_paraphrase1\"][i]\n",
    "    input_emb_p2 = task_2[\"embedding_paraphrase2\"][i]\n",
    "\n",
    "\n",
    "    predicted_label, probabilities = predict_sample(model, tokenizer, input_text, input_label, input_embedding)\n",
    "    predicted_label1, probabilities1 = predict_sample(model, tokenizer, paraphrase_text1, input_label, input_emb_p1)\n",
    "    predicted_label2, probabilities2 = predict_sample(model, tokenizer, paraphrase_text2, input_label, input_emb_p2)\n",
    "\n",
    "    if predicted_label != predicted_label1 and predicted_label != predicted_label2 and predicted_label1 != predicted_label2:\n",
    "        labels = [predicted_label, predicted_label1, predicted_label2]\n",
    "        label1_score = max(probabilities)\n",
    "        label2_score = max(probabilities1)\n",
    "        label3_score = max(probabilities2)\n",
    "        scores = {label1_score: predicted_label, label2_score: predicted_label1, label3_score: predicted_label2}\n",
    "        final_label = max(scores.keys())\n",
    "        predicted_label = scores[final_label]\n",
    "    else:\n",
    "        # Get the most frequent label\n",
    "        predicted_label = max(predicted_label, predicted_label1, predicted_label2, key=[predicted_label, predicted_label1, predicted_label2].count)\n",
    "        \n",
    "    y_pred_ens_task_2.append(predicted_label)\n",
    "\n",
    "y_pred_ens_task_2 = np.array(y_pred_ens_task_2)\n",
    "\n",
    "aux = load_dataset(\"../data/translated_dataset_task2.csv\")\n",
    "\n",
    "ids = aux[\"id\"]\n",
    "\n",
    "preds_task_2_ens = pd.DataFrame(columns=[\"id\", \"label\"])\n",
    "preds_task_2_ens[\"id\"] = ids\n",
    "preds_task_2_ens[\"label\"]= y_pred_ens_task_2\n",
    "preds_task_2_ens[\"label\"] = preds_task_2_ens[\"label\"].apply(lambda x: reverse_mapping[x])\n",
    "preds_task_2_ens.to_csv(\"../data/task2_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
